"""
RUTAS DE REPORTES
Endpoints principales para tabla viva y exportaciones
"""

from fastapi import APIRouter, Depends, Query, HTTPException, Response
from fastapi.responses import FileResponse, StreamingResponse
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import func, case as sql_case, distinct
import io
import logging
from datetime import datetime, timedelta
from typing import Optional
from collections import defaultdict

from app.database import get_db, Case, Company, Employee, CaseDocument, CaseEvent, CaseNote
from app.schemas.reporte import (
    FiltrosExportacion, 
    TablaVivaResponse,
    PreviewExportResponse,
    RegenerarTablaResponse
)
from app.services.reporte_service import ReporteService
from app.utils.excel_formatter import ExcelFormatter
from app.services.prorroga_detector import auto_detectar_prorroga_caso, analizar_historial_empleado
from app.services.cie10_service import buscar_codigo, validar_dias

logger = logging.getLogger(__name__)

# Crear router
router = APIRouter(prefix="/validador/casos", tags=["Reportes"])

# ============================================================
# 1Ô∏è‚É£ ENDPOINT: TABLA VIVA (Auto-refresh cada 30s)
# ============================================================
@router.get("/tabla-viva", response_model=TablaVivaResponse)
async def get_tabla_viva(
    empresa: str = Query("all", description="Nombre de empresa o 'all'"),
    periodo: str = Query("mes_actual", description="Tipo de per√≠odo"),
    db: Session = Depends(get_db)
):
    """
    üìä TABLA VIVA EN TIEMPO REAL
    
    - Se actualiza autom√°ticamente cada 30 segundos desde el frontend
    - Muestra estad√≠sticas por estado
    - Incluye √∫ltimos 20 casos
    
    Par√°metros:
    - empresa: "all" o nombre espec√≠fico
    - periodo: mes_actual, mes_anterior, quincena_1, quincena_2, a√±o_actual
    
    Ejemplo:
    GET /validador/casos/tabla-viva?empresa=all&periodo=mes_actual
    """
    try:
        datos = ReporteService.obtener_tabla_viva(db, empresa, periodo, Case)
        return datos
    except Exception as e:
        logger.error(f"Error tabla viva: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================
# 2Ô∏è‚É£ ENDPOINT: PREVIEW EXPORTACI√ìN (20 registros)
# ============================================================
@router.get("/preview-exportacion", response_model=PreviewExportResponse)
async def get_preview_exportacion(
    empresa: str = Query("all"),
    fecha_inicio: Optional[str] = Query(None, description="YYYY-MM-DD"),
    fecha_fin: Optional[str] = Query(None, description="YYYY-MM-DD"),
    estados: Optional[str] = Query(None, description="estado1,estado2,..."),
    tipos: Optional[str] = Query(None, description="tipo1,tipo2,..."),
    db: Session = Depends(get_db)
):
    """
    üëÅÔ∏è PREVIEW DE EXPORTACI√ìN
    
    - Muestra m√°ximo 20 registros
    - No descarga, solo visualizaci√≥n
    - Usado antes de hacer export final
    
    Par√°metros:
    - empresa: "all" o nombre
    - fecha_inicio/fin: formato YYYY-MM-DD
    - estados: separado por comas
    - tipos: separado por comas
    
    Ejemplo:
    GET /validador/casos/preview-exportacion?empresa=all&estados=COMPLETA,NUEVA
    """
    try:
        filtros = {
            "empresa": empresa,
            "fecha_inicio": fecha_inicio,
            "fecha_fin": fecha_fin,
            "estados": estados,
            "tipos": tipos,
        }
        
        preview = ReporteService.obtener_preview(db, filtros, Case)
        return {
            **preview,
            "periodo": "custom",
            "fecha_inicio": fecha_inicio,
            "fecha_fin": fecha_fin,
        }
    except Exception as e:
        logger.error(f"Error preview: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================
# 3Ô∏è‚É£ ENDPOINT: EXPORTAR AVANZADO (XLSX/CSV/JSON)
# ============================================================
@router.get("/exportar-avanzado")
async def exportar_avanzado(
    empresa: str = Query("all"),
    fecha_inicio: Optional[str] = Query(None, description="YYYY-MM-DD"),
    fecha_fin: Optional[str] = Query(None, description="YYYY-MM-DD"),
    estados: Optional[str] = Query(None, description="estado1,estado2,..."),
    tipos: Optional[str] = Query(None, description="tipo1,tipo2,..."),
    incluir_historial: bool = Query(False),
    formato: str = Query("xlsx", description="xlsx, csv o json"),
    db: Session = Depends(get_db)
):
    """
    üì• EXPORTAR DATOS AVANZADO
    
    - Descarga archivo en 3 formatos: XLSX, CSV, JSON
    - Aplica todos los filtros
    - Excel con formato profesional
    
    Par√°metros:
    - formato: "xlsx", "csv", "json"
    - incluir_historial: True/False
    
    Ejemplo:
    GET /validador/casos/exportar-avanzado?formato=xlsx&empresa=all&estados=COMPLETA
    """
    try:
        filtros = {
            "empresa": empresa,
            "fecha_inicio": fecha_inicio,
            "fecha_fin": fecha_fin,
            "estados": estados,
            "tipos": tipos,
        }
        
        # Obtener datos
        df = ReporteService.obtener_datos_exportacion(
            db, filtros, incluir_historial, Case
        )
        
        # Generar nombre del archivo
        fecha_export = datetime.now().strftime("%Y-%m-%d")
        empresa_nombre = empresa.lower().replace(" ", "_") if empresa != "all" else "todas-empresas"
        
        if formato == "xlsx":
            archivo = ExcelFormatter.crear_excel(df, titulo="Reporte Incapacidades")
            nombre = f"reporte_incapacidades_{empresa_nombre}_{fecha_export}.xlsx"
            media_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        
        elif formato == "csv":
            archivo = ExcelFormatter.crear_csv(df)
            nombre = f"reporte_incapacidades_{empresa_nombre}_{fecha_export}.csv"
            media_type = "text/csv"
        
        elif formato == "json":
            archivo = ExcelFormatter.crear_json(df)
            nombre = f"reporte_incapacidades_{empresa_nombre}_{fecha_export}.json"
            media_type = "application/json"
        
        else:
            raise ValueError("Formato no soportado")
        
        return Response(
            content=archivo,
            media_type=media_type,
            headers={"Content-Disposition": f"attachment; filename={nombre}"}
        )
    
    except Exception as e:
        logger.error(f"Error exportando: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================
# 4Ô∏è‚É£ ENDPOINT: REGENERAR TABLA VIVA (Admin)
# ============================================================
@router.post("/regenerar-tabla-viva", response_model=RegenerarTablaResponse)
async def regenerar_tabla_viva(db: Session = Depends(get_db)):
    """
    üîÑ REGENERAR TABLA VIVA (Archiva mes anterior)
    
    - ‚ö†Ô∏è Uso ADMINISTRATIVO
    - Archiva datos del mes anterior
    - Limpia tabla para nuevo per√≠odo
    - Se ejecuta autom√°ticamente cada 1¬∞ del mes a las 00:01
    
    Uso manual: POST /validador/casos/regenerar-tabla-viva
    """
    try:
        resultado = ReporteService.regenerar_tabla_viva(db, Case)
        logger.info(f"‚úÖ Tabla regenerada: {resultado}")
        return resultado
    except Exception as e:
        logger.error(f"Error regenerando: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================
# ENDPOINT ADICIONAL: HEALTH CHECK
# ============================================================
@router.get("/health")
async def health_check(db: Session = Depends(get_db)):
    """
    ‚úÖ Verificar estado de la API
    
    Retorna:
    - status: "ok"
    - scheduler: "running" o "stopped"
    - database: "connected"
    """
    try:
        # Verificar base de datos
        db.query(Case).limit(1).all()
        
        return {
            "status": "ok",
            "scheduler": "running",
            "database": "connected",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error health check: {str(e)}")
        return {
            "status": "error",
            "scheduler": "unknown",
            "database": "disconnected",
            "error": str(e)
        }


# ============================================================
# 5Ô∏è‚É£ ENDPOINT: DASHBOARD COMPLETO 2026
# ============================================================
def _calcular_fechas_periodo(periodo: str, fecha_desde: str = None, fecha_hasta: str = None):
    """Calcula fechas inicio/fin seg√∫n per√≠odo"""
    import calendar
    hoy = datetime.now()
    if periodo == "personalizado" and fecha_desde and fecha_hasta:
        try:
            inicio = datetime.strptime(fecha_desde, "%Y-%m-%d")
            fin = datetime.strptime(fecha_hasta, "%Y-%m-%d").replace(hour=23, minute=59, second=59)
            return inicio, fin
        except ValueError:
            return datetime(hoy.year, hoy.month, 1), hoy
    elif periodo == "mes_actual":
        return datetime(hoy.year, hoy.month, 1), hoy
    elif periodo == "mes_anterior":
        primer_dia = datetime(hoy.year, hoy.month, 1)
        fin = primer_dia - timedelta(days=1)
        return datetime(fin.year, fin.month, 1), fin
    elif periodo == "quincena_1":
        return datetime(hoy.year, hoy.month, 1), datetime(hoy.year, hoy.month, 15, 23, 59, 59)
    elif periodo == "quincena_2":
        ultimo = calendar.monthrange(hoy.year, hoy.month)[1]
        return datetime(hoy.year, hoy.month, 16), datetime(hoy.year, hoy.month, ultimo, 23, 59, 59)
    elif periodo == "a√±o_actual":
        return datetime(hoy.year, 1, 1), hoy
    elif periodo == "ultimos_90":
        return hoy - timedelta(days=90), hoy
    elif periodo == "todo":
        return datetime(2020, 1, 1), hoy
    else:
        return datetime(hoy.year, hoy.month, 1), hoy


@router.get("/dashboard-completo")
async def get_dashboard_completo(
    empresa: str = Query("all"),
    periodo: str = Query("mes_actual"),
    fecha_desde: str = Query(None, description="Fecha inicio YYYY-MM-DD (solo si periodo=personalizado)"),
    fecha_hasta: str = Query(None, description="Fecha fin YYYY-MM-DD (solo si periodo=personalizado)"),
    db: Session = Depends(get_db)
):
    """
    üìä DASHBOARD COMPLETO 2026
    Retorna TODOS los datos necesarios para el panel de reportes:
    - KPIs generales
    - Tabla principal con TODOS los campos
    - Documentos incompletos con motivos
    - Frecuencia por empleado (reincidencia)
    - Indicadores por estado
    - D√≠as en portal de validaci√≥n
    """
    try:
        fecha_inicio, fecha_fin = _calcular_fechas_periodo(periodo, fecha_desde, fecha_hasta)
        
        # Query base con joins
        query = db.query(Case).options(
            joinedload(Case.empresa),
            joinedload(Case.empleado),
            joinedload(Case.documentos),
            joinedload(Case.eventos),
        ).filter(
            Case.created_at >= fecha_inicio,
            Case.created_at <= fecha_fin
        )
        
        if empresa != "all":
            query = query.join(Company, Case.company_id == Company.id).filter(Company.nombre == empresa)
        
        casos = query.order_by(Case.created_at.desc()).all()
        ahora = datetime.now()
        
        # ‚ïê‚ïê‚ïê 1. KPIs ‚ïê‚ïê‚ïê
        total = len(casos)
        por_estado = defaultdict(int)
        total_dias_incapacidad = 0
        
        for c in casos:
            est = c.estado.value if c.estado else "NUEVO"
            por_estado[est] += 1
            if c.dias_incapacidad:
                total_dias_incapacidad += c.dias_incapacidad
        
        kpis = {
            "total_casos": total,
            "total_dias_incapacidad": total_dias_incapacidad,
            "promedio_dias": round(total_dias_incapacidad / total, 1) if total > 0 else 0,
            "por_estado": dict(por_estado),
            "completas": por_estado.get("COMPLETA", 0),
            "incompletas": por_estado.get("INCOMPLETA", 0) + por_estado.get("ILEGIBLE", 0) + por_estado.get("INCOMPLETA_ILEGIBLE", 0),
            "en_proceso": por_estado.get("NUEVO", 0) + por_estado.get("EN_REVISION", 0),
            "eps_transcripcion": por_estado.get("EPS_TRANSCRIPCION", 0),
            "derivado_tthh": por_estado.get("DERIVADO_TTHH", 0),
        }
        
        # ‚ïê‚ïê‚ïê 2. TABLA PRINCIPAL ‚ïê‚ïê‚ïê
        tabla_principal = []
        for c in casos:
            emp = c.empleado
            emp_nombre = emp.nombre if emp else c.cedula or "N/A"
            emp_area = emp.area_trabajo if emp else None
            emp_eps = emp.eps if emp else c.eps
            empresa_nombre = c.empresa.nombre if c.empresa else "N/A"
            
            # Campos Kactus del empleado
            emp_cargo = emp.cargo if emp else None
            emp_centro_costo = emp.centro_costo if emp else None
            emp_fecha_ingreso = emp.fecha_ingreso.isoformat() if emp and emp.fecha_ingreso else None
            emp_tipo_contrato = emp.tipo_contrato if emp else None
            emp_dias_kactus = emp.dias_kactus if emp else None
            emp_ciudad = emp.ciudad if emp else None
            
            # Calcular d√≠as en portal (desde creaci√≥n hasta ahora o hasta estado final)
            dias_en_portal = (ahora - c.created_at).days if c.created_at else 0
            
            # Obtener √∫ltimo motivo/observaci√≥n de eventos
            ultimo_motivo = None
            if c.eventos:
                evt_con_motivo = [e for e in c.eventos if e.motivo]
                if evt_con_motivo:
                    ultimo_evt = sorted(evt_con_motivo, key=lambda e: e.created_at or datetime.min, reverse=True)[0]
                    ultimo_motivo = ultimo_evt.motivo
            
            # Documentos faltantes
            docs_faltantes = []
            docs_ilegibles = []
            if c.documentos:
                for d in c.documentos:
                    est_doc = d.estado_doc.value if d.estado_doc else "PENDIENTE"
                    if est_doc in ("PENDIENTE", "INCOMPLETO"):
                        docs_faltantes.append(d.doc_tipo)
                    elif est_doc == "ILEGIBLE":
                        docs_ilegibles.append(d.doc_tipo)
            
            # ‚≠ê Auto-detectar pr√≥rroga por CIE-10
            prorroga_auto = {"es_prorroga": False}
            try:
                prorroga_auto = auto_detectar_prorroga_caso(db, c)
            except Exception:
                pass
            
            # ‚≠ê Validar CIE-10 y d√≠as
            cie10_info = None
            dias_validacion = None
            if c.codigo_cie10:
                cie10_info = buscar_codigo(c.codigo_cie10)
                if c.dias_incapacidad:
                    dias_validacion = validar_dias(c.codigo_cie10, c.dias_incapacidad)
            
            tabla_principal.append({
                "serial": c.serial,
                "cedula": c.cedula,
                "nombre": emp_nombre,
                "empresa": empresa_nombre,
                "area": emp_area,
                "cargo": emp_cargo,
                "centro_costo": emp_centro_costo,
                "ciudad": emp_ciudad,
                "tipo_contrato": emp_tipo_contrato,
                "fecha_ingreso": emp_fecha_ingreso,
                "eps": emp_eps or c.eps,
                "tipo": c.tipo.value if c.tipo else "N/A",
                "subtipo": c.subtipo,
                "estado": c.estado.value if c.estado else "NUEVO",
                "diagnostico": c.diagnostico,
                "codigo_cie10": c.codigo_cie10,
                "cie10_descripcion": cie10_info.get("descripcion") if cie10_info else None,
                "cie10_grupo": cie10_info.get("grupo") if cie10_info else None,
                "dias_incapacidad": c.dias_incapacidad,
                "dias_kactus": c.dias_kactus,
                "dias_kactus_empleado": emp_dias_kactus,
                "dias_validacion": dias_validacion,
                "es_prorroga": prorroga_auto.get("es_prorroga", c.es_prorroga),
                "es_prorroga_db": c.es_prorroga,
                "prorroga_confianza": prorroga_auto.get("confianza"),
                "prorroga_explicacion": prorroga_auto.get("explicacion"),
                "prorroga_caso_original": prorroga_auto.get("caso_original_serial"),
                "numero_incapacidad": c.numero_incapacidad,
                "medico_tratante": c.medico_tratante,
                "institucion_origen": c.institucion_origen,
                "fecha_inicio": c.fecha_inicio.isoformat() if c.fecha_inicio else None,
                "fecha_fin": c.fecha_fin.isoformat() if c.fecha_fin else None,
                "fecha_radicacion": c.created_at.isoformat() if c.created_at else None,
                "dias_en_portal": dias_en_portal,
                "observacion": ultimo_motivo,
                "docs_faltantes": docs_faltantes,
                "docs_ilegibles": docs_ilegibles,
                "drive_link": c.drive_link,
            })
        
        # ‚ïê‚ïê‚ïê 3. INCOMPLETAS / OBSERVACI√ìN ‚ïê‚ïê‚ïê
        incompletas = []
        for row in tabla_principal:
            if row["estado"] in ("INCOMPLETA", "ILEGIBLE", "INCOMPLETA_ILEGIBLE"):
                incompletas.append({
                    "serial": row["serial"],
                    "cedula": row["cedula"],
                    "nombre": row["nombre"],
                    "empresa": row["empresa"],
                    "area": row.get("area"),
                    "cargo": row.get("cargo"),
                    "tipo": row["tipo"],
                    "estado": row["estado"],
                    "observacion": row["observacion"],
                    "docs_faltantes": row["docs_faltantes"],
                    "docs_ilegibles": row["docs_ilegibles"],
                    "dias_en_portal": row["dias_en_portal"],
                    "fecha_radicacion": row["fecha_radicacion"],
                    "diagnostico": row.get("diagnostico"),
                    "codigo_cie10": row.get("codigo_cie10"),
                })
        
        # ‚ïê‚ïê‚ïê 4. FRECUENCIA POR EMPLEADO (reincidencia) ‚ïê‚ïê‚ïê
        # Agrupar por c√©dula para detectar personas con m√∫ltiples incapacidades
        freq_query = db.query(Case).filter(
            Case.created_at >= datetime(ahora.year, 1, 1)  # A√±o actual completo
        )
        if empresa != "all":
            freq_query = freq_query.join(Company, Case.company_id == Company.id).filter(Company.nombre == empresa)
        
        todos_casos_a√±o = freq_query.options(joinedload(Case.empleado), joinedload(Case.empresa)).all()
        
        por_cedula = defaultdict(list)
        for c in todos_casos_a√±o:
            if c.cedula:
                por_cedula[c.cedula].append(c)
        
        frecuencia = []
        for cedula, casos_persona in por_cedula.items():
            if len(casos_persona) == 0:
                continue
            primer_caso = casos_persona[0]
            emp = primer_caso.empleado
            nombre = emp.nombre if emp else cedula
            empresa_n = primer_caso.empresa.nombre if primer_caso.empresa else "N/A"
            
            total_dias_persona = sum(c.dias_incapacidad or 0 for c in casos_persona)
            total_dias_kactus = sum(c.dias_kactus or 0 for c in casos_persona)
            diagnosticos = list(set(c.diagnostico for c in casos_persona if c.diagnostico))
            codigos_cie10 = list(set(c.codigo_cie10 for c in casos_persona if c.codigo_cie10))
            prorrogas = sum(1 for c in casos_persona if c.es_prorroga)
            
            # ‚≠ê An√°lisis CIE-10 de historial completo
            analisis_cie10 = None
            alertas_180 = []
            try:
                analisis_cie10 = analizar_historial_empleado(db, cedula)
                alertas_180 = analisis_cie10.get("alertas_180", [])
                # Usar pr√≥rrogas detectadas por CIE-10 si son m√°s que las de BD
                prorrogas_auto = sum(
                    len(c.get("prorrogas", []))
                    for c in analisis_cie10.get("cadenas_prorroga", [])
                )
                if prorrogas_auto > prorrogas:
                    prorrogas = prorrogas_auto
            except Exception:
                pass
            
            # Desglose por mes
            por_mes = defaultdict(int)
            for c in casos_persona:
                if c.created_at:
                    mes_key = c.created_at.strftime("%Y-%m")
                    por_mes[mes_key] += 1
            
            frecuencia.append({
                "cedula": cedula,
                "nombre": nombre,
                "empresa": empresa_n,
                "area": emp.area_trabajo if emp else None,
                "cargo": emp.cargo if emp else None,
                "ciudad": emp.ciudad if emp else None,
                "total_incapacidades": len(casos_persona),
                "total_dias_portal": total_dias_persona,
                "total_dias_kactus": total_dias_kactus,
                "prorrogas": prorrogas,
                "diagnosticos": diagnosticos,
                "codigos_cie10": codigos_cie10,
                "desglose_mensual": dict(por_mes),
                "es_reincidente": len(casos_persona) >= 3,
                "primera_fecha": min(c.created_at for c in casos_persona if c.created_at).isoformat() if any(c.created_at for c in casos_persona) else None,
                "ultima_fecha": max(c.created_at for c in casos_persona if c.created_at).isoformat() if any(c.created_at for c in casos_persona) else None,
                # ‚≠ê Campos nuevos CIE-10
                "alertas_180": alertas_180,
                "tiene_alerta_180": len(alertas_180) > 0,
                "max_cadena_dias": analisis_cie10["resumen"]["cadena_mas_larga_dias"] if analisis_cie10 else 0,
                "dias_prorroga": analisis_cie10.get("dias_prorroga", analisis_cie10["resumen"].get("dias_prorroga", 0)) if analisis_cie10 else 0,
                "cadenas_prorroga": analisis_cie10["resumen"]["cadenas_con_prorroga"] if analisis_cie10 else 0,
                "cerca_limite_180": analisis_cie10["resumen"].get("cerca_limite_180", False) if analisis_cie10 else False,
                "supero_180": analisis_cie10["resumen"].get("supero_180", False) if analisis_cie10 else False,
                # ‚≠ê Huecos (pr√≥rrogas cortadas)
                "huecos_detectados": len(analisis_cie10.get("huecos_detectados", [])) if analisis_cie10 else 0,
                "tiene_huecos": len(analisis_cie10.get("huecos_detectados", [])) > 0 if analisis_cie10 else False,
                "huecos_info": analisis_cie10["resumen"].get("huecos_info", []) if analisis_cie10 else [],
            })
        
        # Ordenar por m√°s incapacidades primero
        frecuencia.sort(key=lambda x: x["total_incapacidades"], reverse=True)
        
        # ‚ïê‚ïê‚ïê 5. INDICADORES POR ESTADO ‚ïê‚ïê‚ïê
        indicadores = []
        for estado, cantidad in sorted(por_estado.items(), key=lambda x: x[1], reverse=True):
            casos_estado = [r for r in tabla_principal if r["estado"] == estado]
            dias_promedio = 0
            if casos_estado:
                dias_vals = [r["dias_incapacidad"] or 0 for r in casos_estado]
                dias_promedio = round(sum(dias_vals) / len(dias_vals), 1) if dias_vals else 0
            
            indicadores.append({
                "estado": estado,
                "cantidad": cantidad,
                "porcentaje": round(cantidad / total * 100, 1) if total > 0 else 0,
                "dias_promedio_incapacidad": dias_promedio,
                "dias_promedio_portal": round(sum(r["dias_en_portal"] for r in casos_estado) / len(casos_estado), 1) if casos_estado else 0,
            })
        
        # ‚ïê‚ïê‚ïê 6. ALERTAS 180 D√çAS GLOBALES ‚ïê‚ïê‚ïê
        alertas_180_global = []
        for f in frecuencia:
            if f.get("alertas_180"):
                alertas_180_global.extend(f["alertas_180"])
        alertas_180_global.sort(key=lambda x: {"critica": 0, "alta": 1, "media": 2}.get(x.get("severidad", ""), 3))
        
        return {
            "ok": True,
            "periodo": periodo,
            "empresa": empresa,
            "fecha_inicio": fecha_inicio.isoformat(),
            "fecha_fin": fecha_fin.isoformat(),
            "fecha_consulta": ahora.isoformat(),
            "kpis": kpis,
            "tabla_principal": tabla_principal,
            "incompletas": incompletas,
            "frecuencia": frecuencia,
            "indicadores": indicadores,
            "alertas_180": alertas_180_global,
        }
    
    except Exception as e:
        logger.error(f"Error dashboard completo: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
